/**
 * $ ./gradlew
 * The default task will build the project and run the test suite inside
 * your local spark environment (spark-submit must be on the PATH).
 *
 * To build and install library, run ./gradlew jar install
 *
 * To generate documentation and docs JAR, run ./gradlew docsJar
 *
 * A coverage report will be present at build/reports/scoverage/index.html
 *
 * TODO integrate https://github.com/kt3k/coveralls-gradle-plugin
 */

buildscript {
  repositories {
    mavenLocal()
    mavenCentral()
    jcenter()
  }
  dependencies {
    classpath 'com.github.maiflai:gradle-scalatest:0.9'
    classpath 'org.scoverage:gradle-scoverage:1.0.9'
    classpath 'org.kt3k.gradle.plugin:coveralls-gradle-plugin:2.4.0'
    classpath 'org.github.ngbinh.scalastyle:gradle-scalastyle-plugin_2.11:0.7.2'
  }
}

apply plugin: 'java'
apply plugin: 'scala'
apply plugin: 'maven'
apply plugin: 'signing'
apply plugin: 'com.github.maiflai.scalatest'
apply plugin: 'scoverage'
apply plugin: 'idea'
apply plugin: 'com.github.kt3k.coveralls'
apply plugin: 'scalaStyle'

sourceCompatibility = 1.7
targetCompatibility = 1.7

repositories {
  mavenLocal()
  mavenCentral()
}

configurations {
  provided
}

group = 'software.uncharted.sparkpipe'
version = '0.9.0'

project.ext {
  scalaBinaryVersion = '2.10'
  scalaVersion = '2.10.4'
  sparkVersion = System.getenv("SPARK_VERSION") ?: '1.5.2'
  scoverageVersion = '1.1.1'
  artifactName = 'sparkpipe-core'
  description = 'A Spark Scala library for creating modular, non-linear data pipelines.'
  inceptionYear = '2015'
  url = 'https://github.com/unchartedsoftware/sparkpipe'
  ossrhUsername = project.hasProperty('ossrhUsername') ? project.getProperty('ossrhUsername') : ''
  ossrhPassword = project.hasProperty('ossrhPassword') ? project.getProperty('ossrhPassword') : ''
}

jar {
  baseName = "${artifactName}"
  version =  version
  dependsOn configurations.runtime
  from {
    (configurations.runtime - configurations.provided).collect {
      it.isDirectory() ? it : zipTree(it)
    }
  } {
    exclude "META-INF/*.SF"
    exclude "META-INF/*.DSA"
    exclude "META-INF/*.RSA"
  }
}

task docs(type: ScalaDoc) {
  source = sourceSets.main.allScala
}

task docsJar(type: Jar, dependsOn: docs) {
  classifier = 'scaladoc'
  from docs.destinationDir
}

task sourcesJar(type: Jar) {
  classifier = 'sources'
  from sourceSets.main.allSource
}

checkScoverage {
  minimumRate = 1
}

task testJar(type: Jar) {
  classifier = 'tests'
  from sourceSets.test.output
}

task test(overwrite: true, type: Exec, dependsOn: [jar, jarScoverage, testJar, docsJar, scalaStyle]) {
  executable = 'spark-submit'
  args = ["--packages","org.mockito:mockito-all:1.10.19,org.scalatest:scalatest_${scalaBinaryVersion}:2.2.5,org.scoverage:scalac-scoverage-runtime_${scalaBinaryVersion}:${scoverageVersion}","--jars","/opt/pipeline/build/libs/${artifactName}-${version}-scoverage.jar","--class","software.uncharted.sparkpipe.Main","build/libs/${artifactName}-${version}-tests.jar"]
}

task debug(overwrite: true, type: Exec, dependsOn: [jar, jarScoverage, testJar, docsJar, scalaStyle]) {
  executable = 'spark-submit'
  environment.put 'SPARK_JAVA_OPTS', '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=9999'
  args = ["--packages","org.scalatest:scalatest_${scalaBinaryVersion}:2.2.5,org.scoverage:scalac-scoverage-runtime_${scalaBinaryVersion}:${scoverageVersion}","--jars","/opt/pipeline/build/libs/${artifactName}-${version}-scoverage.jar","--class","software.uncharted.sparkpipe.Main","build/libs/${artifactName}-${version}-tests.jar"]
}

task coverage(overwrite: true, dependsOn: test) << {
  reportScoverage.execute()
  checkScoverage.execute()
}

coveralls {
  coberturaReportPath = "${buildDir}/reports/scoverage/cobertura.xml"
}

//////////////////////////////////////
//BEGIN nexus oss
//////////////////////////////////////
artifacts {
  archives docsJar, testJar, sourcesJar
}
signing {
  sign configurations.archives
}
//make sure assemble doesn't depend on signing
gradle.taskGraph.whenReady { taskGraph ->
  def tasks = taskGraph.getAllTasks()
  if (tasks.find {it.name == 'assemble'}) {
    tasks.findAll {it.name == 'signArchives' || it.name == 'signDocsJar' || it.name == 'signTestJar' || it.name == 'signSourcesJar'}.each { task ->
      task.enabled = false
    }
  }
}
uploadArchives {
  repositories {
    mavenDeployer {
      beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

      repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots/") {
        authentication(userName: ossrhUsername, password: ossrhPassword)
      }

      pom.project {
        name = artifactName
        packaging = 'jar'
        // optionally artifactId can be defined here
        description = description
        url = url

        scm {
          connection 'scm:git:git://github.com/unchartedsoftware/sparkpipe.git'
          developerConnection 'scm:git:git@github.com:unchartedsoftware/sparkpipe.git'
          url 'https://github.com/unchartedsoftware/sparkpipe'
        }

        licenses {
          license {
            name 'The Apache License, Version 2.0'
            url 'http://www.apache.org/licenses/LICENSE-2.0.txt'
          }
        }

        developers {
          developer {
            id = 'smcintyre'
            name = 'Sean McIntyre'
            email = 'smcintyre@uncharted.software'
          }
        }
      }
    }
  }
}
//////////////////////////////////////
//END nexus oss
//////////////////////////////////////

scalaStyle {
  configLocation = "scalastyle_config.xml"
  includeTestSourceDirectory = true
  source = sourceSets.main.allScala
  testSource = sourceSets.test.allScala
  failOnWarning = true
}

sourceSets {
  main { compileClasspath += configurations.provided }
  test {
    compileClasspath += configurations.provided
    runtimeClasspath += configurations.provided
  }
  scoverage { compileClasspath += configurations.provided }
  testScoverage { compileClasspath += configurations.provided }
}

dependencies {
    //scala
    provided("org.scala-lang:scala-library:${scalaVersion}")

    //spark
    provided "org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}"
    //provided "org.apache.spark:spark-streaming_${scalaBinaryVersion}:${sparkVersion}"
    //provided "org.apache.spark:spark-graphx_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.apache.spark:spark-mllib_${scalaBinaryVersion}:${sparkVersion}"
    provided "org.scala-lang:scala-library:$scalaBinaryVersion"

    //scalatest
    testCompile "org.scalatest:scalatest_${scalaBinaryVersion}:2.2.5"
    testRuntime "org.pegdown:pegdown:1.1.0"

    //mockito
    testCompile "org.mockito:mockito-all:1.10.19"

    //scoverage
    scoverage "org.scoverage:scalac-scoverage-plugin_${scalaBinaryVersion}:${scoverageVersion}",
            "org.scoverage:scalac-scoverage-runtime_${scalaBinaryVersion}:${scoverageVersion}"
}

task wrapper(type: Wrapper) {
    gradleVersion = '2.8'
}

idea {
    module {
        inheritOutputDirs = false
        outputDir = file("$buildDir/classes/main/")
    }
}

defaultTasks 'coverage'
